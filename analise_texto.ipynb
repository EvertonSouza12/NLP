{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Eb_VORLm-SNIC787NvXxipMtbbtn18r6",
      "authorship_tag": "ABX9TyPbKlz8yK/ShGs5o9QT/Yho"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2JHRnMsvU0S",
        "outputId": "3ed1059e-0fbf-4ef5-b4a1-02eb6bfb61d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.11.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.4.1)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=b49b87abe925aaec409062b4cb48baa4e3a79a1133fa79dbeeba49694341176d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia\n",
        "!pip install nltk\n",
        "!pip install scikit-learn\n",
        "import wikipedia\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CORPUS = [\n",
        "'No dia 16/02 recebo um e-mail da Loja alegando divergência de dados e acusando pagamento não autorizado! Sem nenhum detalhe adicional! Simplesmente negam a compra, a fatura permanece, e não explicam nada!Liguei para o atendimento e tive a mesma informação. Fui bem atendido. Como trabalho muito com notebook, realizei novamente a compra e fui informado que o pagamento é estornado em até 48h. Quando entrei no Reclame Aqui, que arrependimento tive! Reclamações de pessoas que há mais de uma semana não recebem o estorno, e de problemas similares ao meu! Espero sinceramente que o valor seja estornado logo e que a segunda compra seja bem procedida, e o produto entregue em tempo. Não tenho nenhum apreço por ter que recorrer a medidas legais! Espero profissionalismo e transparência da empresa, como obrigação com o consumidor!',\n",
        "'Boa tarde, fiz um pedido de dois pneus dia 16/01/2020, quase na mesma hora recebi um e-mail de confirmação do pagamento, que a mercadoria já estava com a transportadora e que a previsão de retirada seria em até 7 dias úteis, achei ótimo, muito rápido, já que seria para colocar no carro para viajar no começo do mês, então fiquei muito satisfeito, ia dar tudo certo! Mais não foi isso q aconteceu, não recebi o e-mail de confirmação até a presente data, ai começou a dor de cabeça, mandei e-mail reclamando da demora do dito cujo e-mail de aprovação para retirada do produto no dia 31-01-2020 sendo q o prazo já tinha passado, a resposta foi a seguinte...Identificamos um problema operacional que atrasou a entrega do seu pedido 281425025, mas já estamos em contato com a transportadora para resolvermos o mais rápido possível.Não se preocupe, acionamos nossa equipe de suporte pelo protocolo 6803089. Já estamos acompanhando todo o processo e retornaremos o contato em 05 (cinco) dias úteis.Pedimos desculpas pelo transtorno e estamos à sua disposição.Protocolo: 6779662 Atenciosamente,Atendimento.com. Pois é a o prazo passou e ninguém entrou em contato, foi aí que mandei outro e-mail, e a resposta já foi outra de três dias.. Já acionamos a área responsável. Não se preocupe, em 03 (três) dias corridos o setor responsável entrará em contato.Pois bem ninguém entrou em contato, mas eu entrei em contato por telefone e quem me atendeu, falou em mais 5 dias para o contato comigo! Pow tá de brincadeira né , até quando isso?! Pior de tudo, é que eles tem o produto na loja, antes de comprar no site, passei na loja, mas estava bem mais caro, então optei por comprar no site e retirar na loja! Porém só libera a retirada do produto, com o e-mail de confirmação do site. Estou indignado com isso, pois já estou pagando o pneu no cartão, sendo que não tenho o produto em mãos.',\n",
        "'Realizei a compra de 4 pneus no dia 21 de janeiro, e escolhi a opção de retirar na loja física, o prazo era de 7 dias. Até hoje não recebi a mercadoria, já liguei incontáveis vezes para o numero do atendimento e não obtenho nenhum tipo de retorno, no começo me falavam que eu tinha que aguardar o e-mail de confirmação para retirada da mercadoria na loja, e agora, quase um mês depois, a única coisa que me falam é que irão verificar e me retornar, mas não me retornam. No dia 05 de fevereiro recebi do atendimento@atendimento.com.br um e-mail (ANEXO) falando que iriam analisar o que aconteceu com o meu pedido e entrariam em contato dentro de 5 dias úteis, pois bem, estou até hoje aguardando e nada. Ontem fui na loja física e me informaram que não podem fazer nada, e que estão aguardando a transportadora. Saindo de lá liguei novamente no telefone do atendimento e fui informada pela atendente que a mercadoria havia voltado para o centro de distribuição pois não havia sido retirada. Em momento algum eu recebi e-mail que a mercadoria estava disponível para retirada, muito pelo contrário, todas as vezes que liguei me falaram que eu tinha que aguardar o e-mail. Inclusive quando fui na loja física a atendente não me informou que a mercadoria já tinha ido pra loja e retornado para o centro de distribuição, ela me disse que estava aguardando a transportadora e que não podia fazer absolutamente nada. É UM TOTAL DESCASO E FALTA DE RESPEITO COM O CONSUMIDOR, FICAMOS SEM RETORNO E AINDA RECEBEMOS INFORMAÇÕES DESENCONTRADAS, NINGUÉM RESOLVE O PROBLEMA, FALAM QUE IRÃO VERIFICAR E RETORNAR MAS NÃO RETORNAM. É A PRIMEIRA E SERÁ A ÚLTIMA VEZ QUE COMPRO NO SITE da Loja, VOCÊS SÃO PÉSSIMOS. ATENDIMENTO HORRÍVEL. COMPREI COM VOCÊS POR CONTA DO PRAZO QUE ESTAVA NO SITE DE VOCÊS POIS TINHA VIAGEM MARCADA, E OLHA SÓ, NÃO CONSEGUI VIAJAR POIS OS PNEUS NÃO CHEGARAM A TEMPO. COMPRAR COM VOCÊS É SÓ PREJUÍZO, NÃO RECOMENDO PARA NINGUÉM.',\n",
        "'No dia 11/02/2020 realizei um pedido de compras on-line no site da Loja. Na tela principal aparece uma promoção do creme dental siga sorrindo, no banner está escrito: compre 3 produtos do creme dental e concorra a R$1000,00* + FRETE GRÁTIS NAS COMPRAS ACIMA DE 39,90. Clicando no banner não existe nenhum regulamento nem mais informações, desta forma inclui na minha compra 3 produtos do creme dental no carrinho e no mesmo momento o valor do frete passou para 0 reais. Conclui a compra no valor de R$391,78 e quando foi cobrado no cartão haviam incluído o frete de R$14,90. As compras chegaram certas e resolvi fazer outro pedido (n 308435373). Ainda constava o mesmo banner de promoção então inclui os 3 produtos do creme dental. Novamente ocorreu o mesmo erro e o frete foi cobrado. Liguei no SAC (protocolo 6918522) e o atendente  me falou que na verdade ao comprar os 3 produtos do creme dental estaria concorrendo aos R$1000,00 da promoção e também concorrendo a um frete grátis. Argumentei que isso era uma propaganda enganosa, pois não estava claro a nenhum momento e não teria lógica participar de um sorteio para ganhar frete grátis!?!Recebi estas segundas compras certas, porém não obedeceram o horário escolhido no site e entregaram 1h antes do combinado, por sorte tinha alguém para receber naquele momento.Entrando no site da promoção do creme dental, existe sim a inclusão dos 3 produtos para concorrer aos R$1000,00 porém não existe nada sobre frete grátis muito menos vinculado aoà Loja. Desta forma solicito a devolução do valor dos fretes.'\n",
        "]\n",
        "new_doc = ['fiz uma compra dia 17/01/2020 e solicitei o máximo de parcelas no caso 15x, ai fui conferir e vi que foi parcelado apenas em 8x, liguei logo depois de 2h pra verificar e solicitar que fosse alterado para 15x assim como eu tinha solicitada, me comunicaram que eu teria que cancelar e fazer novamente a compra, até ai tudo bem eu solicitei o cancelamento com eles para comprar novamente, porém já se passaram 27 dias apás a solicitação do estorno do cartão de crédito, já efetuei várias ligações com dois protocolos em mãos e nada de ser feito o estorno, tive que pagar a primeira parcela que foi lançada na fatura e nada deles estornarem meu cartão, a segunda parcela já esta por vir e nada de estornarem a compra ou liberarem o limite do meu cartão.']\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def bagOfWords(corpus, ngram_range=(1,1)):\n",
        "    vectorizer = CountVectorizer(min_df=1, ngram_range=ngram_range)\n",
        "    caracteristicas = vectorizer.fit_transform(corpus)\n",
        "    return vectorizer, caracteristicas\n",
        "\n",
        "bow_vectorizer, bow_caracteristicas = bagOfWords(CORPUS)\n",
        "caracteristicas = bow_caracteristicas.todense()\n",
        "print (caracteristicas)\n",
        "\n",
        "new_doc_caracteristicas = bow_vectorizer.transform(new_doc)\n",
        "new_doc_caracteristicas = new_doc_caracteristicas.todense()\n",
        "print (new_doc_caracteristicas)\n",
        "\n",
        "feature_names = bow_vectorizer.get_feature_names_out()\n",
        "print (feature_names)\n",
        "\n",
        "#Para apresentar as caracteristicas do texto em forma de dateframe\n",
        "def display_caracteristicas(caracteristicas, feature_names):\n",
        "    df = pd.DataFrame(data=caracteristicas,\n",
        "                      columns=feature_names)\n",
        "    print (df)\n",
        "    df.to_csv(\"saida.csv\", encoding='utf-8')\n",
        "\n",
        "display_caracteristicas(caracteristicas, feature_names)\n",
        "\n",
        "\n",
        "def tfidf_transformer(bow_matrix):\n",
        "    transformer = TfidfTransformer(norm='l2', smooth_idf=True, use_idf=True)\n",
        "    tfidf_matrix = transformer.fit_transform(bow_matrix)\n",
        "    return transformer, tfidf_matrix\n",
        "\n",
        "\n",
        "\n",
        "feature_names = bow_vectorizer.get_feature_names_out()\n",
        "#Para construir um tfidf\n",
        "# Para construir o transformador do tfidf e mostrar o corpus das caracteristicas tfidf\n",
        "tfidf_trans, tdidf_caracteristicas = tfidf_transformer(bow_caracteristicas)\n",
        "caracteristicas = np.round(tdidf_caracteristicas.todense(), 2)\n",
        "display_caracteristicas(caracteristicas, feature_names)\n",
        "nd_tfidf = tfidf_trans.transform(new_doc_caracteristicas).np.asarray\n",
        "nd_caracteristicas = np.round(nd_tfidf.todense(), 2)\n",
        "display_caracteristicas(nd_caracteristicas, feature_names)\n",
        "feature_names = bow_vectorizer.get_feature_names()\n",
        "\n",
        "# Para calcular a frequencia de cada termo\n",
        "tf = bow_caracteristicas.todense()\n",
        "tf = np.array(tf, dtype='float64')\n",
        "#Para exibir as frequencias\n",
        "display_caracteristicas(tf, feature_names)\n",
        "\n",
        "df = np.diff(sp.csc_matrix(bow_caracteristicas, copy=True).indptr)\n",
        "df = 1 + df #Para normalizar os resultados do idf\n",
        "\n",
        "display_caracteristicas([df], feature_names)\n",
        "\n",
        "\n",
        "#Para calcular a frequencia inversa dos documentos (idf)\n",
        "total_docs = 1 + len(CORPUS)\n",
        "idf = 1.0 + np.log(float(total_docs) / df)\n",
        "\n",
        "display_caracteristicas([np.round(idf, 2)], feature_names)\n",
        "\n",
        "#Para calcular a matriz diagonal do idf\n",
        "total_caracteristicas = bow_caracteristicas.shape[1]\n",
        "idf_diag = sp.spdiags(idf, diags=0, m=total_caracteristicas, n=total_caracteristicas)\n",
        "idf = idf_diag.todense()\n",
        "\n",
        "print (np.round(idf, 2))\n",
        "\n",
        "# Para calcular a matriz de termo frequencia do tfidf\n",
        "tfidf = tf * idf\n",
        "#Para apresentar a matriz com as caracteristicas tfidf\n",
        "display_caracteristicas(np.round(tfidf, 2), feature_names)\n",
        "\n",
        "# Minimos quadrados\n",
        "norms = norm(tfidf, axis=1)\n",
        "#Para normalizar a diferenca em cada documento por meio dos minimos quadrados\n",
        "print(\"Minimos quadrados: \",np.round(norms, 2))\n",
        "\n",
        "#Calcula a normalizacao para o tfidf\n",
        "norm_tfidf = tfidf / norms[:, None]\n",
        "#Apresenta a matriz final com o resultado do tfidf\n",
        "display_caracteristicas(np.round(norm_tfidf, 2), feature_names)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EGXsVEc5vwvy",
        "outputId": "de27d6f8-486d-4cc9-8d75-41a23dd2e629"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 1 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 2]\n",
            " [0 0 0 ... 1 1 1]\n",
            " [3 0 1 ... 0 0 0]]\n",
            "[[0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 3 0\n",
            "  0 0 0 0 0 0 0 0 0 2 0 0 0 0 1 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 5 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 3 1 0 0 0 1 2 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 3 0 0 0 0 0 0 0 0 1 1 0 0 0 1 2\n",
            "  0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0\n",
            "  1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 1 0 1 3 0 0 0 0 0 0 1 0 0 2 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
            "  0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0\n",
            "  0 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
            "['00' '01' '02' '03' '05' '1000' '11' '14' '16' '1h' '2020' '21'\n",
            " '281425025' '308435373' '31' '39' '391' '48h' '6779662' '6803089'\n",
            " '6918522' '78' '90' 'absolutamente' 'achei' 'acima' 'acionamos'\n",
            " 'acompanhando' 'aconteceu' 'acusando' 'adicional' 'agora' 'aguardando'\n",
            " 'aguardar' 'ai' 'ainda' 'alegando' 'algum' 'alguém' 'analisar' 'anexo'\n",
            " 'antes' 'ao' 'aos' 'aoà' 'aparece' 'apreço' 'aprovação' 'aqui'\n",
            " 'argumentei' 'arrependimento' 'as' 'atenciosamente' 'atendente' 'atendeu'\n",
            " 'atendido' 'atendimento' 'atrasou' 'até' 'autorizado' 'aí' 'banner' 'bem'\n",
            " 'boa' 'br' 'brincadeira' 'cabeça' 'caro' 'carrinho' 'carro' 'cartão'\n",
            " 'centro' 'certas' 'certo' 'chegaram' 'cinco' 'claro' 'clicando' 'cobrado'\n",
            " 'coisa' 'colocar' 'com' 'combinado' 'começo' 'começou' 'comigo' 'como'\n",
            " 'compra' 'comprar' 'compras' 'compre' 'comprei' 'compro' 'conclui'\n",
            " 'concorra' 'concorrendo' 'concorrer' 'confirmação' 'consegui' 'constava'\n",
            " 'consumidor' 'conta' 'contato' 'contrário' 'corridos' 'creme' 'cujo' 'da'\n",
            " 'dados' 'dar' 'data' 'de' 'demora' 'dental' 'dentro' 'depois' 'descaso'\n",
            " 'desculpas' 'desencontradas' 'desta' 'detalhe' 'devolução' 'dia' 'dias'\n",
            " 'disponível' 'disposição' 'disse' 'distribuição' 'dito' 'divergência'\n",
            " 'do' 'dois' 'dor' 'dos' 'ela' 'eles' 'em' 'empresa' 'enganosa' 'entrando'\n",
            " 'entrariam' 'entrará' 'entrega' 'entregaram' 'entregue' 'entrei' 'entrou'\n",
            " 'então' 'equipe' 'era' 'erro' 'escolhi' 'escolhido' 'escrito' 'espero'\n",
            " 'estamos' 'estaria' 'estas' 'estava' 'estornado' 'estorno' 'estou' 'está'\n",
            " 'estão' 'eu' 'existe' 'explicam' 'falam' 'falando' 'falaram' 'falavam'\n",
            " 'falou' 'falta' 'fatura' 'fazer' 'fevereiro' 'ficamos' 'fiquei' 'fiz'\n",
            " 'foi' 'forma' 'frete' 'fretes' 'fui' 'física' 'ganhar' 'grátis' 'havia'\n",
            " 'haviam' 'hoje' 'hora' 'horrível' 'horário' 'há' 'ia' 'identificamos'\n",
            " 'ido' 'inclui' 'inclusive' 'inclusão' 'incluído' 'incontáveis'\n",
            " 'indignado' 'informada' 'informado' 'informaram' 'informação'\n",
            " 'informações' 'informou' 'iriam' 'irão' 'isso' 'janeiro' 'já' 'legais'\n",
            " 'libera' 'liguei' 'line' 'logo' 'loja' 'lá' 'lógica' 'mail' 'mais'\n",
            " 'mandei' 'marcada' 'mas' 'me' 'medidas' 'menos' 'mercadoria' 'mesma'\n",
            " 'mesmo' 'meu' 'minha' 'momento' 'muito' 'mãos' 'mês' 'na' 'nada'\n",
            " 'naquele' 'nas' 'negam' 'nem' 'nenhum' 'ninguém' 'no' 'nossa' 'notebook'\n",
            " 'novamente' 'numero' 'não' 'né' 'obedeceram' 'obrigação' 'obtenho'\n",
            " 'ocorreu' 'olha' 'on' 'ontem' 'operacional' 'optei' 'opção' 'os' 'outra'\n",
            " 'outro' 'pagamento' 'pagando' 'para' 'participar' 'passado' 'passei'\n",
            " 'passou' 'pedido' 'pedimos' 'pela' 'pelo' 'permanece' 'pessoas' 'pior'\n",
            " 'pneu' 'pneus' 'podem' 'podia' 'pois' 'por' 'porém' 'possível' 'pow'\n",
            " 'pra' 'prazo' 'prejuízo' 'preocupe' 'presente' 'previsão' 'primeira'\n",
            " 'principal' 'problema' 'problemas' 'procedida' 'processo' 'produto'\n",
            " 'produtos' 'profissionalismo' 'promoção' 'propaganda' 'protocolo'\n",
            " 'péssimos' 'quando' 'quase' 'que' 'quem' 'reais' 'realizei' 'recebem'\n",
            " 'recebemos' 'receber' 'recebi' 'recebo' 'reclamando' 'reclamações'\n",
            " 'reclame' 'recomendo' 'recorrer' 'regulamento' 'resolve' 'resolvermos'\n",
            " 'resolvi' 'respeito' 'responsável' 'resposta' 'retirada' 'retirar'\n",
            " 'retornado' 'retornam' 'retornar' 'retornaremos' 'retorno' 'rápido' 'sac'\n",
            " 'saindo' 'satisfeito' 'se' 'seguinte' 'segunda' 'segundas' 'seja' 'sem'\n",
            " 'semana' 'sendo' 'seria' 'será' 'setor' 'seu' 'sido' 'siga' 'sim'\n",
            " 'similares' 'simplesmente' 'sinceramente' 'site' 'sobre' 'solicito'\n",
            " 'sorrindo' 'sorte' 'sorteio' 'sua' 'suporte' 'são' 'só' 'também' 'tarde'\n",
            " 'tela' 'telefone' 'tem' 'tempo' 'tenho' 'ter' 'teria' 'tinha' 'tipo'\n",
            " 'tive' 'todas' 'todo' 'total' 'trabalho' 'transparência' 'transportadora'\n",
            " 'transtorno' 'três' 'tudo' 'tá' 'um' 'uma' 'valor' 'verdade' 'verificar'\n",
            " 'vez' 'vezes' 'viagem' 'viajar' 'vinculado' 'vocês' 'voltado' 'área'\n",
            " 'ótimo' 'última' 'única' 'úteis']\n",
            "   00  01  02  03  05  1000  11  14  16  1h  ...  viagem  viajar  vinculado  \\\n",
            "0   0   0   1   0   0     0   0   0   1   0  ...       0       0          0   \n",
            "1   0   2   0   1   1     0   0   0   1   0  ...       0       1          0   \n",
            "2   0   0   0   0   1     0   0   0   0   0  ...       1       1          0   \n",
            "3   3   0   1   0   0     3   1   1   0   1  ...       0       0          1   \n",
            "\n",
            "   vocês  voltado  área  ótimo  última  única  úteis  \n",
            "0      0        0     0      0       0      0      0  \n",
            "1      0        0     1      1       0      0      2  \n",
            "2      4        1     0      0       1      1      1  \n",
            "3      0        0     0      0       0      0      0  \n",
            "\n",
            "[4 rows x 410 columns]\n",
            "     00    01    02    03    05  1000    11    14    16    1h  ...  viagem  \\\n",
            "0  0.00  0.00  0.07  0.00  0.00  0.00  0.00  0.00  0.07  0.00  ...    0.00   \n",
            "1  0.00  0.09  0.00  0.04  0.03  0.00  0.00  0.00  0.03  0.00  ...    0.00   \n",
            "2  0.00  0.00  0.00  0.00  0.03  0.00  0.00  0.00  0.00  0.00  ...    0.04   \n",
            "3  0.14  0.00  0.04  0.00  0.00  0.14  0.05  0.05  0.00  0.05  ...    0.00   \n",
            "\n",
            "   viajar  vinculado  vocês  voltado  área  ótimo  última  única  úteis  \n",
            "0    0.00       0.00   0.00     0.00  0.00   0.00    0.00   0.00   0.00  \n",
            "1    0.03       0.00   0.00     0.00  0.04   0.04    0.00   0.00   0.07  \n",
            "2    0.03       0.00   0.17     0.04  0.00   0.00    0.04   0.04   0.03  \n",
            "3    0.00       0.05   0.00     0.00  0.00   0.00    0.00   0.00   0.00  \n",
            "\n",
            "[4 rows x 410 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-da3eaa997a1a>\u001b[0m in \u001b[0;36m<cell line: 55>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mcaracteristicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdidf_caracteristicas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mdisplay_caracteristicas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaracteristicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mnd_tfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_trans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_doc_caracteristicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mnd_caracteristicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mdisplay_caracteristicas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd_caracteristicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1708\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m         \"\"\"\n\u001b[0;32m-> 1710\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m   1711\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \"\"\"\n\u001b[1;32m    736\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;34m\"np.matrix is not supported. Please convert to a numpy array with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;34m\"np.asarray. For more information see: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: np.matrix is not supported. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html"
          ]
        }
      ]
    }
  ]
}